{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import nltk\nimport string\nimport numpy as np\nimport pandas as pd\n\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom collections import defaultdict, Counter\n\nimport re\nfrom nltk.tokenize import word_tokenize\nimport gensim\nimport string\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom tqdm import tqdm\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading & viewing dataset.\n- References [link_1](https://github.com/Nhan121/Kaggle-6-first-projects/blob/master/NLP_Text_Classification/NLP_Text_classification.ipynb)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path = r'../input/nlp-getting-started'\ntrain = pd.read_csv(path + '/train.csv')\ntrain.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## 1. Pre-processing\n### 1.1. Counting & handling missing-values"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame({'count_NA': train.isna().sum(), \n              '%NA': round(100*train.isna().sum() / train.shape[0], 2), \n              'type' :train.dtypes})","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"          count_NA    %NA    type\nid               0   0.00   int64\nkeyword         61   0.80  object\nlocation      2533  33.27  object\ntext             0   0.00  object\ntarget           0   0.00   int64","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count_NA</th>\n      <th>%NA</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>id</th>\n      <td>0</td>\n      <td>0.00</td>\n      <td>int64</td>\n    </tr>\n    <tr>\n      <th>keyword</th>\n      <td>61</td>\n      <td>0.80</td>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>location</th>\n      <td>2533</td>\n      <td>33.27</td>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>text</th>\n      <td>0</td>\n      <td>0.00</td>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>target</th>\n      <td>0</td>\n      <td>0.00</td>\n      <td>int64</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### Comment.\n- For the column `keyword`, it takes about `0.8%` at both dataset; whilethe column `location` is more than `33%`. Both of them (both columns) are the `object` types so we can replace the missing values by `unknown` to keep the structure preservation.\n- The rest columns `id, text, target` (in `train.csv`) and `id, text` (in `test.csv`) has no missing value since we will predict the `target` (and add them to the `test`) mainly based on the `text`."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.fillna('unknown')\ntrain.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"   id  keyword location                                               text  \\\n0   1  unknown  unknown  Our Deeds are the Reason of this #earthquake M...   \n1   4  unknown  unknown             Forest fire near La Ronge Sask. Canada   \n2   5  unknown  unknown  All residents asked to 'shelter in place' are ...   \n3   6  unknown  unknown  13,000 people receive #wildfires evacuation or...   \n4   7  unknown  unknown  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>unknown</td>\n      <td>unknown</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>unknown</td>\n      <td>unknown</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>unknown</td>\n      <td>unknown</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>unknown</td>\n      <td>unknown</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>unknown</td>\n      <td>unknown</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 1.2. Droping duplicated-values\n#### The unique-values."},{"metadata":{"trusted":true},"cell_type":"code","source":"count_unique = [len(train[col].unique()) for col in train.columns]\npercent_uniq = [round(100*cnt / train.shape[0], 2) for cnt in count_unique]\npd.DataFrame({'cnt_uniq': count_unique, 'perc_uniq_%': percent_uniq}, index = train.columns)","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"          cnt_uniq  perc_uniq_%\nid            7613       100.00\nkeyword        222         2.92\nlocation      3342        43.90\ntext          7503        98.56\ntarget           2         0.03","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cnt_uniq</th>\n      <th>perc_uniq_%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>id</th>\n      <td>7613</td>\n      <td>100.00</td>\n    </tr>\n    <tr>\n      <th>keyword</th>\n      <td>222</td>\n      <td>2.92</td>\n    </tr>\n    <tr>\n      <th>location</th>\n      <td>3342</td>\n      <td>43.90</td>\n    </tr>\n    <tr>\n      <th>text</th>\n      <td>7503</td>\n      <td>98.56</td>\n    </tr>\n    <tr>\n      <th>target</th>\n      <td>2</td>\n      <td>0.03</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### Droping the duplicates values (after ignore the `id`)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_non_id = train.drop(columns = ['id'])\ntrain_non_id = train_non_id.drop_duplicates()\ntrain_non_id.shape","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"(7561, 4)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 1.3. Text-processing."},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pyspellchecker","execution_count":7,"outputs":[{"output_type":"stream","text":"Collecting pyspellchecker\n  Downloading pyspellchecker-0.5.6-py2.py3-none-any.whl (2.5 MB)\n\u001b[K     |████████████████████████████████| 2.5 MB 2.1 MB/s eta 0:00:01     |██                              | 153 kB 414 kB/s eta 0:00:06\n\u001b[?25hInstalling collected packages: pyspellchecker\nSuccessfully installed pyspellchecker-0.5.6\n\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"The following function is prepared for the Section 3.2 (Model using `text-processing`)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nfrom spellchecker import SpellChecker    \n\ndef process_text(str_input):\n    ## 1. Remove url_link\n    remove_url = re.compile(r'https?://\\S+|www\\.\\S+').sub(r'', str_input)\n    \n    ## 2. Remove html_link\n    remove_html = re.compile(r'<.*?>').sub(r'', remove_url)\n    \n    ## 3. Remove Emojis\n    remove_emo = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE).sub(r'', remove_html)\n    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", remove_emo).lower().split()    \n        \n    ## 4. spell_correction\n    #spell = SpellChecker()\n    #words = [spell.correction(word) for word in words[:50]]\n\n    return words\n\n## Review the first 5 lines after using text-processing\nnew_train = train.copy()\n%time new_train.loc[:5, 'correct_text'] = train.loc[:5, 'text'].apply(lambda x: process_text(x))\nnew_train.head()","execution_count":8,"outputs":[{"output_type":"stream","text":"CPU times: user 9.16 ms, sys: 754 µs, total: 9.91 ms\nWall time: 9.56 ms\n","name":"stdout"},{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"   id  keyword location                                               text  \\\n0   1  unknown  unknown  Our Deeds are the Reason of this #earthquake M...   \n1   4  unknown  unknown             Forest fire near La Ronge Sask. Canada   \n2   5  unknown  unknown  All residents asked to 'shelter in place' are ...   \n3   6  unknown  unknown  13,000 people receive #wildfires evacuation or...   \n4   7  unknown  unknown  Just got sent this photo from Ruby #Alaska as ...   \n\n   target                                       correct_text  \n0       1  [our, deeds, are, the, reason, of, this, earth...  \n1       1      [forest, fire, near, la, ronge, sask, canada]  \n2       1  [all, residents, asked, to, shelter, in, place...  \n3       1  [13, 000, people, receive, wildfires, evacuati...  \n4       1  [just, got, sent, this, photo, from, ruby, ala...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n      <th>correct_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>unknown</td>\n      <td>unknown</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n      <td>[our, deeds, are, the, reason, of, this, earth...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>unknown</td>\n      <td>unknown</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>unknown</td>\n      <td>unknown</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n      <td>[all, residents, asked, to, shelter, in, place...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>unknown</td>\n      <td>unknown</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n      <td>[13, 000, people, receive, wildfires, evacuati...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>unknown</td>\n      <td>unknown</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n      <td>[just, got, sent, this, photo, from, ruby, ala...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## 2. Grid-Seach CV.\n### 2.1. Initialize the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Text_length'] = train['text'].str.len()\ntrain['Numb_words'] = train['text'].str.split().map(lambda x: len(x))\ntrain = train.set_index('id')\ntrain.head()","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"    keyword location                                               text  \\\nid                                                                        \n1   unknown  unknown  Our Deeds are the Reason of this #earthquake M...   \n4   unknown  unknown             Forest fire near La Ronge Sask. Canada   \n5   unknown  unknown  All residents asked to 'shelter in place' are ...   \n6   unknown  unknown  13,000 people receive #wildfires evacuation or...   \n7   unknown  unknown  Just got sent this photo from Ruby #Alaska as ...   \n\n    target  Text_length  Numb_words  \nid                                   \n1        1           69          13  \n4        1           38           7  \n5        1          133          22  \n6        1           65           8  \n7        1           88          16  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n      <th>Text_length</th>\n      <th>Numb_words</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>unknown</td>\n      <td>unknown</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n      <td>69</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>unknown</td>\n      <td>unknown</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n      <td>38</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>unknown</td>\n      <td>unknown</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n      <td>133</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>unknown</td>\n      <td>unknown</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n      <td>65</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>unknown</td>\n      <td>unknown</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n      <td>88</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Train-test split.\n- 2 columns `keyword, location` has so many categories so that it can not be used to establish the model.\n- It make more time in computation and the efficients is not good."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize the tfidf_vectorizer \nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf_vectorizer = TfidfVectorizer(stop_words = 'english') \nX = tfidf_vectorizer.fit_transform(train['text']) \n\n## Target\ny = train['target']","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.3, random_state=42)\n\nX_train.shape, X_test.shape, y_train.shape","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"((5329, 21363), (2284, 21363), (5329,))"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 2.2. Lauching with SVM model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\nfrom sklearn.model_selection import GridSearchCV\n\nsvm = svm.SVC()\ngrid_params = [{\n                'kernel':['linear', 'rbf', 'poly'],\n                'C': [0.1, 1, 5], #default: 1.0\n                 }]\nclf = GridSearchCV(estimator=svm, param_grid = grid_params, cv = 8, verbose = 0)\n%time clf.fit(X_train, y_train)","execution_count":12,"outputs":[{"output_type":"stream","text":"CPU times: user 3min 38s, sys: 4.04 s, total: 3min 42s\nWall time: 3min 42s\n","name":"stdout"},{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"GridSearchCV(cv=8, estimator=SVC(),\n             param_grid=[{'C': [0.1, 1, 5],\n                          'kernel': ['linear', 'rbf', 'poly']}])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.best_params_","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"{'C': 1, 'kernel': 'linear'}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.best_score_","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"0.7907679043361202"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\npred_train = clf.predict(X_train)\npred_test = clf.predict(X_test)\n\nprint(accuracy_score(y_train, pred_train))\nprint(accuracy_score(y_test, pred_test))","execution_count":15,"outputs":[{"output_type":"stream","text":"0.9502720960780634\n0.8104203152364273\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_train, pred_train))\nprint(confusion_matrix(y_test, pred_test))","execution_count":16,"outputs":[{"output_type":"stream","text":"[[2994   45]\n [ 220 2070]]\n[[1178  125]\n [ 308  673]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(columns = ['best_params', 'train_acc_%', 'train_conf_matrix', 'test_acc_%', 'test_conf_matrix'])\ndf.loc['SVM'] = [clf.best_params_, \n                 100*accuracy_score(y_train, pred_train), confusion_matrix(y_train, pred_train), \n                 100*accuracy_score(y_test, pred_test), confusion_matrix(y_test, pred_test)]\ndf","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"                      best_params  train_acc_%          train_conf_matrix  \\\nSVM  {'C': 1, 'kernel': 'linear'}     95.02721  [[2994, 45], [220, 2070]]   \n\n     test_acc_%           test_conf_matrix  \nSVM   81.042032  [[1178, 125], [308, 673]]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>best_params</th>\n      <th>train_acc_%</th>\n      <th>train_conf_matrix</th>\n      <th>test_acc_%</th>\n      <th>test_conf_matrix</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>SVM</th>\n      <td>{'C': 1, 'kernel': 'linear'}</td>\n      <td>95.02721</td>\n      <td>[[2994, 45], [220, 2070]]</td>\n      <td>81.042032</td>\n      <td>[[1178, 125], [308, 673]]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## 3. And for another model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nX_train_num = train[['Text_length', 'Numb_words']].to_numpy()\nX_con = StandardScaler().fit_transform(X_train_num)\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nX_C = CountVectorizer(analyzer = process_text).fit_transform(train['text'])\n\nX_train, X_test, y_train, y_test = train_test_split(X_C, y, stratify = y, test_size=0.3, random_state=0)\n\nX_train.shape, X_test.shape, y_train.shape","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"((5329, 17330), (2284, 17330), (5329,))"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 3.1. Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB, GaussianNB\n\nnaiv = MultinomialNB()\ngrid_params = [{'alpha' : [0.5, 0.75, 0.8, 1]}]\nclf = GridSearchCV(estimator=naiv, param_grid = grid_params, cv = 5, verbose = 0)\n%time clf.fit(X_train, y_train)\n\npred_train = clf.predict(X_train)\npred_test = clf.predict(X_test)\n\nprint(clf.best_params_)\nprint(accuracy_score(y_train, pred_train))\nprint(accuracy_score(y_test, pred_test))\n\ndf.loc['MultiNB'] = [clf.best_params_, \n                     100*accuracy_score(y_train, pred_train), confusion_matrix(y_train, pred_train), \n                     100*accuracy_score(y_test, pred_test), confusion_matrix(y_test, pred_test)]","execution_count":19,"outputs":[{"output_type":"stream","text":"CPU times: user 124 ms, sys: 991 µs, total: 125 ms\nWall time: 124 ms\n{'alpha': 1}\n0.903921936573466\n0.8025394045534151\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### 3.2. Logistic-Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.3, random_state=42)\nlogreg = LogisticRegression()\ngrid_params = [{'C' : [0.5, 1, 2, 10],\n                'max_iter': [500, 1000]}]\nclf = GridSearchCV(estimator = logreg, param_grid = grid_params, cv = 15, verbose = 0)\n%time clf.fit(X_train, y_train)\n\npred_train = clf.predict(X_train)\npred_test = clf.predict(X_test)\n\nprint(clf.best_params_)\nprint(accuracy_score(y_train, pred_train))\nprint(accuracy_score(y_test, pred_test))\n\ndf.loc['Log-reg'] = [clf.best_params_, \n                     100*accuracy_score(y_train, pred_train), confusion_matrix(y_train, pred_train), \n                     100*accuracy_score(y_test, pred_test), confusion_matrix(y_test, pred_test)]","execution_count":20,"outputs":[{"output_type":"stream","text":"CPU times: user 45 s, sys: 630 ms, total: 45.6 s\nWall time: 23 s\n{'C': 2, 'max_iter': 500}\n0.9356352036029274\n0.8042907180385289\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### 3.3. K-Nearest-Neighbors Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\ngrid_params = [{'n_neighbors': [50, 80, 100, 150]}]\n\nclf = GridSearchCV(estimator = knn, param_grid = grid_params, cv = 5, verbose = 0)\n%time clf.fit(X_train, y_train)\n\npred_train = clf.predict(X_train)\npred_test = clf.predict(X_test)\n\nprint(clf.best_params_)\nprint(accuracy_score(y_train, pred_train))\nprint(accuracy_score(y_test, pred_test))\n\ndf.loc['K-nn'] = [clf.best_params_, \n                  100*accuracy_score(y_train, pred_train), confusion_matrix(y_train, pred_train), \n                  100*accuracy_score(y_test, pred_test), confusion_matrix(y_test, pred_test)]","execution_count":21,"outputs":[{"output_type":"stream","text":"CPU times: user 3.07 s, sys: 143 ms, total: 3.22 s\nWall time: 3.17 s\n{'n_neighbors': 100}\n0.7766935635203603\n0.7863397548161121\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### 3.4. Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier()\nX_train, X_test, y_train, y_test = train_test_split(X_C, y, stratify = y, test_size=0.3, random_state=42)\ngrid_params = [{\n                'n_estimators': [200, 300], #default=10\n                'criterion': ['gini'], #default=”gini”\n                'max_depth': [5, 10, 20], #default=None\n                'oob_score': [True], #default=False\n                'random_state': [0, 42, 88]\n                 }]\n\nclf = GridSearchCV(estimator = rfc, param_grid = grid_params, cv = 5, verbose = 0)\n%time clf.fit(X_train, y_train)\n\npred_train = clf.predict(X_train)\npred_test = clf.predict(X_test)\n\nprint(clf.best_params_)\nprint(accuracy_score(y_train, pred_train))\nprint(accuracy_score(y_test, pred_test))\n\ndf.loc['rfc'] = [clf.best_params_, \n                 100*accuracy_score(y_train, pred_train), confusion_matrix(y_train, pred_train), \n                 100*accuracy_score(y_test, pred_test), confusion_matrix(y_test, pred_test)]","execution_count":22,"outputs":[{"output_type":"stream","text":"CPU times: user 3min 46s, sys: 666 ms, total: 3min 47s\nWall time: 3min 47s\n{'criterion': 'gini', 'max_depth': 20, 'n_estimators': 300, 'oob_score': True, 'random_state': 88}\n0.7350347157065116\n0.717600700525394\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### 3.5. XGB Classifier."},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgb = XGBClassifier()\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.3, random_state=42)\ngrid_params = [{\n                'n_estimators': [500, 1000, 5000],\n                'learning_rate': [.05, 0.1],\n                'max_depth': [5, 7, 10],\n            }]\nclf = GridSearchCV(estimator = xgb, param_grid = grid_params, cv = 5, verbose = 0)\n%time clf.fit(X_train, y_train,eval_set=[(X_train, y_train), (X_test, y_test)], early_stopping_rounds = 20, verbose = 0)","execution_count":23,"outputs":[{"output_type":"stream","text":"CPU times: user 47min 44s, sys: 1min 40s, total: 49min 24s\nWall time: 12min 42s\n","name":"stdout"},{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"GridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, gamma=None,\n                                     gpu_id=None, importance_type='gain',\n                                     interaction_constraints=None,\n                                     learning_rate=None, max_delta_step=None,\n                                     max_depth=None, min_child_weight=None,\n                                     missing=nan, monotone_constraints=None,\n                                     n_estimators=100, n_jobs=None,\n                                     num_parallel_tree=None, random_state=None,\n                                     reg_alpha=None, reg_lambda=None,\n                                     scale_pos_weight=None, subsample=None,\n                                     tree_method=None, validate_parameters=None,\n                                     verbosity=None),\n             param_grid=[{'learning_rate': [0.05, 0.1], 'max_depth': [5, 7, 10],\n                          'n_estimators': [500, 1000, 5000]}])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(clf.best_params_)\nprint(accuracy_score(y_train, pred_train))\nprint(accuracy_score(y_test, pred_test))\n\ndf.loc['XGB-simple'] = [clf.best_params_, \n                         100*accuracy_score(y_train, pred_train), confusion_matrix(y_train, pred_train), \n                         100*accuracy_score(y_test, pred_test), confusion_matrix(y_test, pred_test)]","execution_count":24,"outputs":[{"output_type":"stream","text":"{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n0.7350347157065116\n0.717600700525394\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### XGB with complexity-model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\n\nclass TextSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, field):\n        self.field = field\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        return X[self.field]\n    \nclass NumberSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, field):\n        self.field = field\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        return X[[self.field]]","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nfrom sklearn.svm import SVC\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nsvc = SVC()\n\nX_t = train[['text', 'Text_length']]\nX_train, X_test, y_train, y_test = train_test_split(X_t, \n                                                    y, \n                                                    test_size = 0.3, \n                                                    stratify = y, \n                                                    random_state = 42)\nclf = Pipeline([\n    (\n        'features', FeatureUnion([\n        ('text', Pipeline([\n            ('colext', TextSelector('text')),\n            ('tfidf', TfidfVectorizer(tokenizer = process_text, stop_words = 'english',\n                     min_df = .0025, max_df = 0.25, ngram_range = (1, 5) ) ),\n            ('svd', TruncatedSVD(algorithm ='randomized', n_components = 300) ), #for XGB\n        ])),\n        ('words', Pipeline([\n            ('wordext', NumberSelector('Text_length')),\n            ('wscaler', StandardScaler()),\n        ])),            \n    ])\n    ),\n    ('clf', XGBClassifier(eval_set=[(X_train, y_train), (X_test, y_test)],\n                          max_depth = 8, n_estimators = 500, base_estimator = svc, learning_rate = 0.1, cv = 15))\n    ])\n\n## Fit the model\nstart = time.time()\nclf.fit(X_train, y_train)\npred_train = clf.predict(X_train)\npred_test = clf.predict(X_test)\nprint ('Fit&trainning time : ', time.time() - start)\n\ntrain_acc_Xgb2 = accuracy_score(y_train, clf.predict(X_train)) * 100.0 \ntest_acc_Xgb2 = accuracy_score(y_test, pred_test) * 100.0\n\nprint(\"Training_Accuracy: %.2f%%\" % train_acc_Xgb2)\nprint(\"Testing_Accuracy: %.2f%%\" % test_acc_Xgb2)","execution_count":26,"outputs":[{"output_type":"stream","text":"[09:39:48] WARNING: ../src/learner.cc:516: \nParameters: { base_estimator, cv, eval_set } might not be used.\n\n  This may not be accurate due to some parameters are only used in language bindings but\n  passed down to XGBoost core.  Or some parameters are not used but slip through this\n  verification. Please open an issue if you find above cases.\n\n\nFit&trainning time :  66.12007093429565\nTraining_Accuracy: 99.02%\nTesting_Accuracy: 77.01%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc['XGB-complex'] = [\"\", \n                         100*accuracy_score(y_train, pred_train), confusion_matrix(y_train, pred_train), \n                         100*accuracy_score(y_test, pred_test), confusion_matrix(y_test, pred_test)]","execution_count":27,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.6. Adaboost"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\nX_t = train[['text', 'Numb_words']]\nX_train, X_test, y_train, y_test = train_test_split(X_t, \n                                                    y, \n                                                    test_size = 0.3, \n                                                    stratify = y, \n                                                    random_state = 42)\n\nclf = Pipeline([\n    (\n        'features', FeatureUnion([\n        ('text', Pipeline([\n            ('colext', TextSelector('text')),\n            ('tfidf', TfidfVectorizer(tokenizer = process_text, stop_words = 'english',\n                     min_df = .0025, max_df = 0.25, ngram_range = (1, 5) ) ),\n            ('svd', TruncatedSVD(algorithm ='randomized', n_components = 300) ), \n        ])),\n        ('words', Pipeline([\n            ('wordext', NumberSelector('Numb_words')),\n            ('wscaler', StandardScaler()),\n        ])),            \n    ])\n    ),\n    ('clf', AdaBoostClassifier(n_estimators = 300, learning_rate = 0.1)),\n    ])\n\nstart = time.time()\n%time clf.fit(X_train, y_train)\npred_train = clf.predict(X_train)\npred_test = clf.predict(X_test)\n\ndf.loc['Ada_Bst-complex'] = [\"\", \n                             100*accuracy_score(y_train, pred_train), confusion_matrix(y_train, pred_train), \n                             100*accuracy_score(y_test, pred_test), confusion_matrix(y_test, pred_test)]\ndf","execution_count":28,"outputs":[{"output_type":"stream","text":"CPU times: user 1min 9s, sys: 56.4 ms, total: 1min 9s\nWall time: 1min 9s\n","name":"stdout"},{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"                                                       best_params  \\\nSVM                                   {'C': 1, 'kernel': 'linear'}   \nMultiNB                                               {'alpha': 1}   \nLog-reg                                  {'C': 2, 'max_iter': 500}   \nK-nn                                          {'n_neighbors': 100}   \nrfc              {'criterion': 'gini', 'max_depth': 20, 'n_esti...   \nXGB-simple       {'learning_rate': 0.1, 'max_depth': 10, 'n_est...   \nXGB-complex                                                          \nAda_Bst-complex                                                      \n\n                 train_acc_%           train_conf_matrix  test_acc_%  \\\nSVM                95.027210   [[2994, 45], [220, 2070]]   81.042032   \nMultiNB            90.392194  [[2917, 122], [390, 1900]]   80.253940   \nLog-reg            93.563520   [[2991, 48], [295, 1995]]   80.429072   \nK-nn               77.669356  [[2649, 390], [800, 1490]]   78.633975   \nrfc                73.503472    [[3039, 0], [1412, 878]]   71.760070   \nXGB-simple         73.503472    [[3039, 0], [1412, 878]]   71.760070   \nXGB-complex        99.024207    [[3026, 13], [39, 2251]]   77.014011   \nAda_Bst-complex    77.575530  [[2690, 349], [846, 1444]]   75.043783   \n\n                          test_conf_matrix  \nSVM              [[1178, 125], [308, 673]]  \nMultiNB          [[1122, 181], [270, 711]]  \nLog-reg          [[1180, 123], [324, 657]]  \nK-nn             [[1122, 181], [307, 674]]  \nrfc               [[1292, 11], [634, 347]]  \nXGB-simple        [[1292, 11], [634, 347]]  \nXGB-complex      [[1115, 188], [337, 644]]  \nAda_Bst-complex  [[1120, 183], [387, 594]]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>best_params</th>\n      <th>train_acc_%</th>\n      <th>train_conf_matrix</th>\n      <th>test_acc_%</th>\n      <th>test_conf_matrix</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>SVM</th>\n      <td>{'C': 1, 'kernel': 'linear'}</td>\n      <td>95.027210</td>\n      <td>[[2994, 45], [220, 2070]]</td>\n      <td>81.042032</td>\n      <td>[[1178, 125], [308, 673]]</td>\n    </tr>\n    <tr>\n      <th>MultiNB</th>\n      <td>{'alpha': 1}</td>\n      <td>90.392194</td>\n      <td>[[2917, 122], [390, 1900]]</td>\n      <td>80.253940</td>\n      <td>[[1122, 181], [270, 711]]</td>\n    </tr>\n    <tr>\n      <th>Log-reg</th>\n      <td>{'C': 2, 'max_iter': 500}</td>\n      <td>93.563520</td>\n      <td>[[2991, 48], [295, 1995]]</td>\n      <td>80.429072</td>\n      <td>[[1180, 123], [324, 657]]</td>\n    </tr>\n    <tr>\n      <th>K-nn</th>\n      <td>{'n_neighbors': 100}</td>\n      <td>77.669356</td>\n      <td>[[2649, 390], [800, 1490]]</td>\n      <td>78.633975</td>\n      <td>[[1122, 181], [307, 674]]</td>\n    </tr>\n    <tr>\n      <th>rfc</th>\n      <td>{'criterion': 'gini', 'max_depth': 20, 'n_esti...</td>\n      <td>73.503472</td>\n      <td>[[3039, 0], [1412, 878]]</td>\n      <td>71.760070</td>\n      <td>[[1292, 11], [634, 347]]</td>\n    </tr>\n    <tr>\n      <th>XGB-simple</th>\n      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n      <td>73.503472</td>\n      <td>[[3039, 0], [1412, 878]]</td>\n      <td>71.760070</td>\n      <td>[[1292, 11], [634, 347]]</td>\n    </tr>\n    <tr>\n      <th>XGB-complex</th>\n      <td></td>\n      <td>99.024207</td>\n      <td>[[3026, 13], [39, 2251]]</td>\n      <td>77.014011</td>\n      <td>[[1115, 188], [337, 644]]</td>\n    </tr>\n    <tr>\n      <th>Ada_Bst-complex</th>\n      <td></td>\n      <td>77.575530</td>\n      <td>[[2690, 349], [846, 1444]]</td>\n      <td>75.043783</td>\n      <td>[[1120, 183], [387, 594]]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}